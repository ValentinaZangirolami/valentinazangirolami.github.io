## Research {.central}

My research focuses on [Statistical Reinforcement Learning]{style="color: palevioletred; font-weight: bold;"} both online and offline.

::: {style="display: flex; justify-content: space-between; align-items: center;"}
<figure style="width: 45%; text-align: center;">

<img src="images/online_rl.gif" alt="Left GIF" style="width: 100%;"/>

<figcaption>[Google Deep Mind](https://deepmind.google/discover/blog/rl-unplugged-benchmarks-for-offline-reinforcement-learning/)</figcaption>

</figure>

<figure style="width: 45%; text-align: center;">

<img src="images/rl.gif" alt="Right GIF" style="width: 100%;"/>

<figcaption>[Google Deep Mind](https://deepmind.google/discover/blog/rl-unplugged-benchmarks-for-offline-reinforcement-learning/)</figcaption>

</figure>
:::

## Papers {.central}

[Articles in refereed journals]{.palevioletred}

1.  **Zangirolami, V.**, and Borrotti, M. (2024). Dealing with uncertainty: balancing exploration and exploitation in deep recurrent reinforcement learning. *Knowledge-Based Systems*, **293**.


## Conferences {.central}

[Invited talk]{.palevioletred}

1.  **Zangirolami, V.** (2024). Enhancing data efficiency in online deep reinforcement learning under partial observability. *18th International Conference of the ERCIM WG on Computational and Methodological Statistics, 13â€“16 December 2024, London (UK)*.

